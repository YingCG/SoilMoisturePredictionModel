{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp (UTC+12:00)</th>\n",
       "      <th>Rain(mm)</th>\n",
       "      <th>SoilTemp(c)</th>\n",
       "      <th>SoilMoisture(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-07 11:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>37.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-07 11:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>37.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-07 11:45:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>37.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-07 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>37.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-07 12:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>37.584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Timestamp (UTC+12:00)  Rain(mm)  SoilTemp(c)  SoilMoisture(%)\n",
       "0   2018-07-07 11:15:00       0.0         10.4           37.364\n",
       "1   2018-07-07 11:30:00       0.0         10.4           37.594\n",
       "2   2018-07-07 11:45:00       0.0         10.4           37.590\n",
       "3   2018-07-07 12:00:00       0.0         10.5           37.587\n",
       "4   2018-07-07 12:15:00       0.0         10.5           37.584"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mtalbert = pd.read_csv('../SoilMoistureResearch/Data/soil data/mtalbert-648717-20241008172730/MtAlbert_Data_15mins.csv', parse_dates=['Timestamp (UTC+12:00)'])\n",
    "mtalbert.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_files = [\n",
    "    '../Data/soil data/mtalbert-648717-20241008172730/MtAlbert_Data_15mins.csv',\n",
    "    '../Data/soil data/Ararimu Zanders 647510-20240909095405/ArarimuCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/Awhitu-741611-20240910095744/awhituCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/HoteoatOldfields-643510-20240909094142/hoteoCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/Kaipara Heads-644211-20240909095124/Kaipara_Data_15mins.csv',\n",
    "    '../Data/soil data/MangemangeroaCraigs649937-20240910100813/mangemangeroaCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/TamahungaQuintalsRd-643713-20240909094554/tamahungaCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/Tomarata64068001-20240910095547/tomarataCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/WaitangiDiverRoad742736-20240910101133/waitangiCombined_Data_15mins.csv',\n",
    "    '../Data/soil data/Whangamarie741813-20240910102615/whangamarieCombined_Data_15mins.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info = {\n",
    "    'Location': ['Kaipara Heads @ Wallers', 'Hoteo at Oldfields', 'Tamahunga @ Quintals Rd',\n",
    "                 'Tomarata at Briens Farm', 'Ararimu @ Zanders', 'Mt Albert Grammer rainfall',\n",
    "                 'Mangemangeroa @ craigs', 'Awhitu @ Brook Road', 'Waitangi @ Diver Road', \n",
    "                 'Whangamaire @ Culvert'],\n",
    "    'Soil order': ['Brown', 'Ultic', 'Ultic', 'Ultic', 'Allophanic', 'Ultic', \n",
    "                   'Ultic', 'Granular', 'Granular', 'Allophanic'],\n",
    "    'NZ Soil Classification': ['Red Hill sandy loam', 'Typic Yellow Ultic', 'Typic Yellow Ultic', \n",
    "                              'Perch Gley or Densipan Ultic', 'Typic Orthic Allophanic', \n",
    "                              'Mottled Yellow Ultic', 'Typic Yellow Ultic', \n",
    "                              'Typic Orthic Granular', 'Typic Orthic Granular', \n",
    "                              'Typic Orthic Allophanic'],\n",
    "    'Mean annual rainfall (mm)': [1054, 1347, 1561, 1172, 1352, 1242, 1198, 1372, 1280, 1329],\n",
    "    'Pastoral land use': ['Drystock', 'Lifestyle block', 'Drystock', 'Dairy', \n",
    "                          'Drystock', 'Mixed dairy and drystock', 'Lifestyle block', \n",
    "                          'Regional Park', 'Dairy', 'Lifestyle block'],\n",
    "    'Ecological District': ['Kaipara', 'Rodney', 'Rodney', 'Rodney', 'Waitakere', \n",
    "                           'Tamaki', 'Tamaki', 'Awhitu', 'Manukau', 'Manukau']\n",
    "}\n",
    "\n",
    "info_df = pd.DataFrame(additional_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Soil order</th>\n",
       "      <th>NZ Soil Classification</th>\n",
       "      <th>Mean annual rainfall (mm)</th>\n",
       "      <th>Pastoral land use</th>\n",
       "      <th>Ecological District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaipara Heads @ Wallers</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Red Hill sandy loam</td>\n",
       "      <td>1054</td>\n",
       "      <td>Drystock</td>\n",
       "      <td>Kaipara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoteo at Oldfields</td>\n",
       "      <td>Ultic</td>\n",
       "      <td>Typic Yellow Ultic</td>\n",
       "      <td>1347</td>\n",
       "      <td>Lifestyle block</td>\n",
       "      <td>Rodney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamahunga @ Quintals Rd</td>\n",
       "      <td>Ultic</td>\n",
       "      <td>Typic Yellow Ultic</td>\n",
       "      <td>1561</td>\n",
       "      <td>Drystock</td>\n",
       "      <td>Rodney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tomarata at Briens Farm</td>\n",
       "      <td>Ultic</td>\n",
       "      <td>Perch Gley or Densipan Ultic</td>\n",
       "      <td>1172</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>Rodney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ararimu @ Zanders</td>\n",
       "      <td>Allophanic</td>\n",
       "      <td>Typic Orthic Allophanic</td>\n",
       "      <td>1352</td>\n",
       "      <td>Drystock</td>\n",
       "      <td>Waitakere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Location  Soil order        NZ Soil Classification  \\\n",
       "0  Kaipara Heads @ Wallers       Brown           Red Hill sandy loam   \n",
       "1       Hoteo at Oldfields       Ultic            Typic Yellow Ultic   \n",
       "2  Tamahunga @ Quintals Rd       Ultic            Typic Yellow Ultic   \n",
       "3  Tomarata at Briens Farm       Ultic  Perch Gley or Densipan Ultic   \n",
       "4        Ararimu @ Zanders  Allophanic       Typic Orthic Allophanic   \n",
       "\n",
       "   Mean annual rainfall (mm) Pastoral land use Ecological District  \n",
       "0                       1054          Drystock             Kaipara  \n",
       "1                       1347   Lifestyle block              Rodney  \n",
       "2                       1561          Drystock              Rodney  \n",
       "3                       1172             Dairy              Rodney  \n",
       "4                       1352          Drystock           Waitakere  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/soil data/mtalbert-648717-20241008172730/MtAlbert_Data_15mins.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Loop through each file, read and clean the data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m station_files:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Read CSV\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Convert the timestamp column to datetime\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp (UTC+12:00)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp (UTC+12:00)\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Ying\\.conda\\envs\\level8\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ying\\.conda\\envs\\level8\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Ying\\.conda\\envs\\level8\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ying\\.conda\\envs\\level8\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Ying\\.conda\\envs\\level8\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/soil data/mtalbert-648717-20241008172730/MtAlbert_Data_15mins.csv'"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "\n",
    "# Loop through each file, read and clean the data\n",
    "for file in station_files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Convert the timestamp column to datetime\n",
    "    df['Timestamp (UTC+12:00)'] = pd.to_datetime(df['Timestamp (UTC+12:00)'])\n",
    "    \n",
    "    # Optionally, clean column names if needed (e.g., removing spaces)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Extract location from file path (you can adjust this as needed)\n",
    "    location = file.split('/')[2].split('-')[0]\n",
    "    \n",
    "    # Add location information to DataFrame\n",
    "    df['Location'] = location\n",
    "    \n",
    "    # Append to list\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Merge with additional information\n",
    "final_df = combined_df.merge(info_df, on='Location', how='left')\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp (UTC+12:00)    0\n",
       "Rain(mm)                 0\n",
       "SoilTemp(c)              0\n",
       "SoilMoisture(%)          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the number of missing entries in each column\n",
    "mtalbert.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blackfriday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Handling missing data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m blackfriday[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct_Category_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct_Category_3\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mblackfriday\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct_Category_2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct_Category_3\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      3\u001b[0m blackfriday\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'blackfriday' is not defined"
     ]
    }
   ],
   "source": [
    "# Handling missing data\n",
    "blackfriday[['Product_Category_2', 'Product_Category_3']] = blackfriday[['Product_Category_2', 'Product_Category_3']].fillna(0).astype(int)\n",
    "blackfriday.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   User_ID                     550068 non-null  int64 \n",
      " 1   Product_ID                  550068 non-null  object\n",
      " 2   Gender                      550068 non-null  object\n",
      " 3   Age                         550068 non-null  object\n",
      " 4   Occupation                  550068 non-null  int64 \n",
      " 5   City_Category               550068 non-null  object\n",
      " 6   Stay_In_Current_City_Years  550068 non-null  object\n",
      " 7   Marital_Status              550068 non-null  int64 \n",
      " 8   Product_Category_1          550068 non-null  int64 \n",
      " 9   Product_Category_2          550068 non-null  int32 \n",
      " 10  Product_Category_3          550068 non-null  int32 \n",
      " 11  Purchase                    550068 non-null  int64 \n",
      "dtypes: int32(2), int64(5), object(5)\n",
      "memory usage: 46.2+ MB\n"
     ]
    }
   ],
   "source": [
    "blackfriday.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardizing your data by address Inconsistencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace age '55+' with '55-100'\n",
    "blackfriday['Age'].replace('55+', '55-100', inplace=True)\n",
    "\n",
    "#  replace Stay_In_Current_City_Years '4+' with 4\n",
    "blackfriday['Stay_In_Current_City_Years'].replace('4+', 4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-17', '18-25', '26-35', '36-45', '46-50', '51-55', '55-100']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(blackfriday['Age'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "blackfriday['Stay_In_Current_City_Years'] = pd.to_numeric(blackfriday['Stay_In_Current_City_Years'])\n",
    "print(sorted(blackfriday['Stay_In_Current_City_Years'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   User_ID                     550068 non-null  int64 \n",
      " 1   Product_ID                  550068 non-null  object\n",
      " 2   Gender                      550068 non-null  object\n",
      " 3   Age                         550068 non-null  object\n",
      " 4   Occupation                  550068 non-null  int64 \n",
      " 5   City_Category               550068 non-null  object\n",
      " 6   Stay_In_Current_City_Years  550068 non-null  int64 \n",
      " 7   Marital_Status              550068 non-null  int64 \n",
      " 8   Product_Category_1          550068 non-null  int64 \n",
      " 9   Product_Category_2          550068 non-null  int32 \n",
      " 10  Product_Category_3          550068 non-null  int32 \n",
      " 11  Purchase                    550068 non-null  int64 \n",
      "dtypes: int32(2), int64(6), object(4)\n",
      "memory usage: 46.2+ MB\n"
     ]
    }
   ],
   "source": [
    "blackfriday.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Occupation_0</th>\n",
       "      <th>Occupation_1</th>\n",
       "      <th>Occupation_2</th>\n",
       "      <th>Occupation_3</th>\n",
       "      <th>Occupation_4</th>\n",
       "      <th>Occupation_5</th>\n",
       "      <th>Occupation_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_Category_3_9</th>\n",
       "      <th>Product_Category_3_10</th>\n",
       "      <th>Product_Category_3_11</th>\n",
       "      <th>Product_Category_3_12</th>\n",
       "      <th>Product_Category_3_13</th>\n",
       "      <th>Product_Category_3_14</th>\n",
       "      <th>Product_Category_3_15</th>\n",
       "      <th>Product_Category_3_16</th>\n",
       "      <th>Product_Category_3_17</th>\n",
       "      <th>Product_Category_3_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>8370</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>15200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>1422</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>1057</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>7969</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID  Purchase  Occupation_0  Occupation_1  Occupation_2  \\\n",
       "0  1000001  P00069042      8370         False         False         False   \n",
       "1  1000001  P00248942     15200         False         False         False   \n",
       "2  1000001  P00087842      1422         False         False         False   \n",
       "3  1000001  P00085442      1057         False         False         False   \n",
       "4  1000002  P00285442      7969         False         False         False   \n",
       "\n",
       "   Occupation_3  Occupation_4  Occupation_5  Occupation_6  ...  \\\n",
       "0         False         False         False         False  ...   \n",
       "1         False         False         False         False  ...   \n",
       "2         False         False         False         False  ...   \n",
       "3         False         False         False         False  ...   \n",
       "4         False         False         False         False  ...   \n",
       "\n",
       "   Product_Category_3_9  Product_Category_3_10  Product_Category_3_11  \\\n",
       "0                 False                  False                  False   \n",
       "1                 False                  False                  False   \n",
       "2                 False                  False                  False   \n",
       "3                 False                  False                  False   \n",
       "4                 False                  False                  False   \n",
       "\n",
       "   Product_Category_3_12  Product_Category_3_13  Product_Category_3_14  \\\n",
       "0                  False                  False                  False   \n",
       "1                  False                  False                   True   \n",
       "2                  False                  False                  False   \n",
       "3                  False                  False                  False   \n",
       "4                  False                  False                  False   \n",
       "\n",
       "   Product_Category_3_15  Product_Category_3_16  Product_Category_3_17  \\\n",
       "0                  False                  False                  False   \n",
       "1                  False                  False                  False   \n",
       "2                  False                  False                  False   \n",
       "3                  False                  False                  False   \n",
       "4                  False                  False                  False   \n",
       "\n",
       "   Product_Category_3_18  \n",
       "0                  False  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                  False  \n",
       "4                  False  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_encode = ['Occupation','Marital_Status', 'Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years','Product_Category_1' , 'Product_Category_2', 'Product_Category_3']\n",
    "\n",
    "# Use the pd.get_dummies() function to perform one-hot encoding\n",
    "blackfriday_encoded = pd.get_dummies(blackfriday, columns=columns_to_encode)\n",
    "blackfriday_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 97 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   User_ID                       550068 non-null  int64 \n",
      " 1   Product_ID                    550068 non-null  object\n",
      " 2   Purchase                      550068 non-null  int64 \n",
      " 3   Occupation_0                  550068 non-null  bool  \n",
      " 4   Occupation_1                  550068 non-null  bool  \n",
      " 5   Occupation_2                  550068 non-null  bool  \n",
      " 6   Occupation_3                  550068 non-null  bool  \n",
      " 7   Occupation_4                  550068 non-null  bool  \n",
      " 8   Occupation_5                  550068 non-null  bool  \n",
      " 9   Occupation_6                  550068 non-null  bool  \n",
      " 10  Occupation_7                  550068 non-null  bool  \n",
      " 11  Occupation_8                  550068 non-null  bool  \n",
      " 12  Occupation_9                  550068 non-null  bool  \n",
      " 13  Occupation_10                 550068 non-null  bool  \n",
      " 14  Occupation_11                 550068 non-null  bool  \n",
      " 15  Occupation_12                 550068 non-null  bool  \n",
      " 16  Occupation_13                 550068 non-null  bool  \n",
      " 17  Occupation_14                 550068 non-null  bool  \n",
      " 18  Occupation_15                 550068 non-null  bool  \n",
      " 19  Occupation_16                 550068 non-null  bool  \n",
      " 20  Occupation_17                 550068 non-null  bool  \n",
      " 21  Occupation_18                 550068 non-null  bool  \n",
      " 22  Occupation_19                 550068 non-null  bool  \n",
      " 23  Occupation_20                 550068 non-null  bool  \n",
      " 24  Marital_Status_0              550068 non-null  bool  \n",
      " 25  Marital_Status_1              550068 non-null  bool  \n",
      " 26  Gender_F                      550068 non-null  bool  \n",
      " 27  Gender_M                      550068 non-null  bool  \n",
      " 28  Age_0-17                      550068 non-null  bool  \n",
      " 29  Age_18-25                     550068 non-null  bool  \n",
      " 30  Age_26-35                     550068 non-null  bool  \n",
      " 31  Age_36-45                     550068 non-null  bool  \n",
      " 32  Age_46-50                     550068 non-null  bool  \n",
      " 33  Age_51-55                     550068 non-null  bool  \n",
      " 34  Age_55-100                    550068 non-null  bool  \n",
      " 35  City_Category_A               550068 non-null  bool  \n",
      " 36  City_Category_B               550068 non-null  bool  \n",
      " 37  City_Category_C               550068 non-null  bool  \n",
      " 38  Stay_In_Current_City_Years_0  550068 non-null  bool  \n",
      " 39  Stay_In_Current_City_Years_1  550068 non-null  bool  \n",
      " 40  Stay_In_Current_City_Years_2  550068 non-null  bool  \n",
      " 41  Stay_In_Current_City_Years_3  550068 non-null  bool  \n",
      " 42  Stay_In_Current_City_Years_4  550068 non-null  bool  \n",
      " 43  Product_Category_1_1          550068 non-null  bool  \n",
      " 44  Product_Category_1_2          550068 non-null  bool  \n",
      " 45  Product_Category_1_3          550068 non-null  bool  \n",
      " 46  Product_Category_1_4          550068 non-null  bool  \n",
      " 47  Product_Category_1_5          550068 non-null  bool  \n",
      " 48  Product_Category_1_6          550068 non-null  bool  \n",
      " 49  Product_Category_1_7          550068 non-null  bool  \n",
      " 50  Product_Category_1_8          550068 non-null  bool  \n",
      " 51  Product_Category_1_9          550068 non-null  bool  \n",
      " 52  Product_Category_1_10         550068 non-null  bool  \n",
      " 53  Product_Category_1_11         550068 non-null  bool  \n",
      " 54  Product_Category_1_12         550068 non-null  bool  \n",
      " 55  Product_Category_1_13         550068 non-null  bool  \n",
      " 56  Product_Category_1_14         550068 non-null  bool  \n",
      " 57  Product_Category_1_15         550068 non-null  bool  \n",
      " 58  Product_Category_1_16         550068 non-null  bool  \n",
      " 59  Product_Category_1_17         550068 non-null  bool  \n",
      " 60  Product_Category_1_18         550068 non-null  bool  \n",
      " 61  Product_Category_1_19         550068 non-null  bool  \n",
      " 62  Product_Category_1_20         550068 non-null  bool  \n",
      " 63  Product_Category_2_0          550068 non-null  bool  \n",
      " 64  Product_Category_2_2          550068 non-null  bool  \n",
      " 65  Product_Category_2_3          550068 non-null  bool  \n",
      " 66  Product_Category_2_4          550068 non-null  bool  \n",
      " 67  Product_Category_2_5          550068 non-null  bool  \n",
      " 68  Product_Category_2_6          550068 non-null  bool  \n",
      " 69  Product_Category_2_7          550068 non-null  bool  \n",
      " 70  Product_Category_2_8          550068 non-null  bool  \n",
      " 71  Product_Category_2_9          550068 non-null  bool  \n",
      " 72  Product_Category_2_10         550068 non-null  bool  \n",
      " 73  Product_Category_2_11         550068 non-null  bool  \n",
      " 74  Product_Category_2_12         550068 non-null  bool  \n",
      " 75  Product_Category_2_13         550068 non-null  bool  \n",
      " 76  Product_Category_2_14         550068 non-null  bool  \n",
      " 77  Product_Category_2_15         550068 non-null  bool  \n",
      " 78  Product_Category_2_16         550068 non-null  bool  \n",
      " 79  Product_Category_2_17         550068 non-null  bool  \n",
      " 80  Product_Category_2_18         550068 non-null  bool  \n",
      " 81  Product_Category_3_0          550068 non-null  bool  \n",
      " 82  Product_Category_3_3          550068 non-null  bool  \n",
      " 83  Product_Category_3_4          550068 non-null  bool  \n",
      " 84  Product_Category_3_5          550068 non-null  bool  \n",
      " 85  Product_Category_3_6          550068 non-null  bool  \n",
      " 86  Product_Category_3_8          550068 non-null  bool  \n",
      " 87  Product_Category_3_9          550068 non-null  bool  \n",
      " 88  Product_Category_3_10         550068 non-null  bool  \n",
      " 89  Product_Category_3_11         550068 non-null  bool  \n",
      " 90  Product_Category_3_12         550068 non-null  bool  \n",
      " 91  Product_Category_3_13         550068 non-null  bool  \n",
      " 92  Product_Category_3_14         550068 non-null  bool  \n",
      " 93  Product_Category_3_15         550068 non-null  bool  \n",
      " 94  Product_Category_3_16         550068 non-null  bool  \n",
      " 95  Product_Category_3_17         550068 non-null  bool  \n",
      " 96  Product_Category_3_18         550068 non-null  bool  \n",
      "dtypes: bool(94), int64(2), object(1)\n",
      "memory usage: 61.9+ MB\n"
     ]
    }
   ],
   "source": [
    "blackfriday_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Import Libraries:\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Prepare Data:\n",
    "\n",
    "# Split the data into features and target\n",
    "# Define features and target\n",
    "X =  blackfriday_encoded[[ 'Occupation_0', 'Occupation_1',\n",
    "       'Occupation_2', 'Occupation_3', 'Occupation_4', 'Occupation_5',\n",
    "       'Occupation_6', 'Occupation_7', 'Occupation_8', 'Occupation_9',\n",
    "       'Occupation_10', 'Occupation_11', 'Occupation_12', 'Occupation_13',\n",
    "       'Occupation_14', 'Occupation_15', 'Occupation_16', 'Occupation_17',\n",
    "       'Occupation_18', 'Occupation_19', 'Occupation_20', 'Marital_Status_0',\n",
    "       'Marital_Status_1', 'Gender_F', 'Gender_M', 'Age_0-17', 'Age_18-25',\n",
    "       'Age_26-35', 'Age_36-45', 'Age_46-50', 'Age_51-55', 'Age_55-100',\n",
    "       'City_Category_A', 'City_Category_B', 'City_Category_C',\n",
    "       'Stay_In_Current_City_Years_0', 'Stay_In_Current_City_Years_1',\n",
    "       'Stay_In_Current_City_Years_2', 'Stay_In_Current_City_Years_3',\n",
    "       'Stay_In_Current_City_Years_4', 'Product_Category_1_1',\n",
    "       'Product_Category_1_2', 'Product_Category_1_3', 'Product_Category_1_4',\n",
    "       'Product_Category_1_5', 'Product_Category_1_6', 'Product_Category_1_7',\n",
    "       'Product_Category_1_8', 'Product_Category_1_9', 'Product_Category_1_10',\n",
    "       'Product_Category_1_11', 'Product_Category_1_12',\n",
    "       'Product_Category_1_13', 'Product_Category_1_14',\n",
    "       'Product_Category_1_15', 'Product_Category_1_16',\n",
    "       'Product_Category_1_17', 'Product_Category_1_18',\n",
    "       'Product_Category_1_19', 'Product_Category_1_20',\n",
    "       'Product_Category_2_0', 'Product_Category_2_2', 'Product_Category_2_3',\n",
    "       'Product_Category_2_4', 'Product_Category_2_5', 'Product_Category_2_6',\n",
    "       'Product_Category_2_7', 'Product_Category_2_8', 'Product_Category_2_9',\n",
    "       'Product_Category_2_10', 'Product_Category_2_11',\n",
    "       'Product_Category_2_12', 'Product_Category_2_13',\n",
    "       'Product_Category_2_14', 'Product_Category_2_15',\n",
    "       'Product_Category_2_16', 'Product_Category_2_17',\n",
    "       'Product_Category_2_18', 'Product_Category_3_0', 'Product_Category_3_3',\n",
    "       'Product_Category_3_4', 'Product_Category_3_5', 'Product_Category_3_6',\n",
    "       'Product_Category_3_8', 'Product_Category_3_9', 'Product_Category_3_10',\n",
    "       'Product_Category_3_11', 'Product_Category_3_12',\n",
    "       'Product_Category_3_13', 'Product_Category_3_14',\n",
    "       'Product_Category_3_15', 'Product_Category_3_16',\n",
    "       'Product_Category_3_17', 'Product_Category_3_18'\n",
    "]].values\n",
    "y = blackfriday_encoded[['Purchase']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Split Data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ying\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Testing Set Metrics:\n",
      "MAE: 2216.912333111453\n",
      "MSE: 9288465.693088328\n",
      "RMSE: 3047.6984255480934\n",
      "R2 Score: 0.6303271840984528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "def evaluate_model(predictions, y_test):\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "rf_mae, rf_mse, rf_rmse, rf_r2 = evaluate_model(rf_predictions, y_test)\n",
    "\n",
    "print(\"\\nRandom Forest Testing Set Metrics:\")\n",
    "print(f\"MAE: {rf_mae}\")\n",
    "print(f\"MSE: {rf_mse}\")\n",
    "print(f\"RMSE: {rf_rmse}\")\n",
    "print(f\"R2 Score: {rf_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
